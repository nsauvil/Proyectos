{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YdqUAkKXF_AU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#from matplotlib import pyplot as plt\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "#import cv2\n",
        "import os\n",
        "#from sklearn import utils\n",
        "import json\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos los tensores y otros datos necesarios para el modelo\n",
        "X_train = np.load('/content/drive/MyDrive/Colab Notebooks/X_train.npy')\n",
        "#X_test = np.load('/content/drive/MyDrive/Colab Notebooks/X_test.npy')\n",
        "y_train = np.load('/content/drive/MyDrive/Colab Notebooks/y_train.npy')\n",
        "#y_test = np.load('/content/drive/MyDrive/Colab Notebooks/y_test.npy')\n",
        "target_names = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\"]\n",
        "num_targets = len(target_names)"
      ],
      "metadata": {
        "id": "AztaNu7xGL68"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SEGUNDO MODELO:\n",
        "# CNN aumentado\n",
        "\n",
        "# Modelo aumentado sobre el modelo base: es decir, que añade más capas a la arquitectura convolucional anterior.\n",
        "\n",
        "model2 = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150,150,3)), #32 filtros. kernel 3x3.\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(num_targets, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CteGapT9GQwB",
        "outputId": "2110f10b-f2ab-4eeb-c0d0-bdeb49c6949c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "model2.compile(optimizer='adam',\n",
        "                 loss='sparse_categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "\n",
        "hist_model2 = model2.fit(X_train, y_train,\n",
        "                  batch_size = 32,\n",
        "                  epochs = 15,\n",
        "                  validation_split = 0.20,\n",
        "                  callbacks  = [early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUzNp6EJGTYh",
        "outputId": "5a6ac93f-8414-48e0-839a-1afa986623d8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 75ms/step - accuracy: 0.4293 - loss: 1.4724 - val_accuracy: 0.5772 - val_loss: 1.0713\n",
            "Epoch 2/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.6315 - loss: 0.9323 - val_accuracy: 0.6888 - val_loss: 0.8552\n",
            "Epoch 3/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.7142 - loss: 0.7556 - val_accuracy: 0.7125 - val_loss: 0.8524\n",
            "Epoch 4/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.7680 - loss: 0.5825 - val_accuracy: 0.7193 - val_loss: 0.7707\n",
            "Epoch 5/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.8553 - loss: 0.4012 - val_accuracy: 0.6900 - val_loss: 1.1314\n",
            "Epoch 6/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9208 - loss: 0.2435 - val_accuracy: 0.7486 - val_loss: 0.9310\n",
            "Epoch 7/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9339 - loss: 0.1920 - val_accuracy: 0.7632 - val_loss: 1.0391\n",
            "Epoch 8/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9804 - loss: 0.0715 - val_accuracy: 0.7057 - val_loss: 1.4025\n",
            "Epoch 9/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9764 - loss: 0.0729 - val_accuracy: 0.7384 - val_loss: 1.2916\n",
            "Epoch 10/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9861 - loss: 0.0448 - val_accuracy: 0.7306 - val_loss: 1.2527\n",
            "CPU times: user 23.1 s, sys: 6.61 s, total: 29.7 s\n",
            "Wall time: 1min 1s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.save('/content/drive/MyDrive/Colab Notebooks/model2.h5')\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/hist_model2.json', 'w') as f:\n",
        "    json.dump(hist_model2.history, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JiIL4ZmGV8_",
        "outputId": "d2fec685-57c4-4250-9c7a-0d56c927dd32"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    }
  ]
}