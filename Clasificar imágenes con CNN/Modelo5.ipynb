{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "butY7WPLGLuI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#from matplotlib import pyplot as plt\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential, load_model\n",
        "#from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "#import cv2\n",
        "import os\n",
        "#from sklearn import utils\n",
        "import json\n",
        "from keras.optimizers import Adam\n",
        "#from keras.applications import InceptionV3\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos los tensores y otros datos necesarios para el modelo\n",
        "X_train = np.load('/content/drive/MyDrive/Colab Notebooks/X_train.npy')\n",
        "#X_test = np.load('/content/drive/MyDrive/Colab Notebooks/X_test.npy')\n",
        "y_train = np.load('/content/drive/MyDrive/Colab Notebooks/y_train.npy')\n",
        "#y_test = np.load('/content/drive/MyDrive/Colab Notebooks/y_test.npy')\n",
        "target_names = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\"]\n",
        "num_targets = len(target_names)"
      ],
      "metadata": {
        "id": "7AxmnKpDGiIV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# QUINTO MODELO:\n",
        "# Aumento de datos (sobre el mejor modelo)\n",
        "\n",
        "# Modelo basado en aumento de datos sobre cualquiera de los cuatro modelos implementados anteriormente\n",
        "# (se aconseja sobre el modelo que mayor score haya devuelto la función evaluate).\n",
        "# Para el aumento de datos, debe emplearse lafunción ImageDataGenerator, la elección de parámetros en ImageDataGeneratores libre.\n",
        "\n",
        "# El mejor modelo es el cuarto (Inceptionv3):\n",
        "model5 = load_model('/content/drive/MyDrive/Colab Notebooks/model4.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqZn-Ea6HA4e",
        "outputId": "064b40df-4a11-4629-9dad-298e3f09bc6c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    validation_split=0.2,\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "datagen.fit(X_train)\n",
        "\n",
        "train_generator = datagen.flow(X_train, y_train, batch_size=32, subset='training')\n",
        "validation_generator = datagen.flow(X_train, y_train, batch_size=32, subset='validation')\n"
      ],
      "metadata": {
        "id": "QtUcvL7HGmFW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Asegurar que eager execution está activado\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "# Recompilar el modelo ANTES de entrenar\n",
        "model5.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "\n",
        "hist_model5 = model5.fit(train_generator,\n",
        "                    batch_size = 32,\n",
        "                    epochs = 15,\n",
        "                    validation_data = validation_generator,\n",
        "                    callbacks  = [early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxRBRwYSJx5h",
        "outputId": "d575583c-d50e-466c-b710-74e808dc0723"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m889s\u001b[0m 8s/step - accuracy: 0.6096 - loss: 1.0486 - val_accuracy: 0.2077 - val_loss: 2.1661\n",
            "Epoch 2/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m931s\u001b[0m 8s/step - accuracy: 0.7248 - loss: 0.7299 - val_accuracy: 0.3251 - val_loss: 1.6825\n",
            "Epoch 3/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m862s\u001b[0m 8s/step - accuracy: 0.7510 - loss: 0.6471 - val_accuracy: 0.5869 - val_loss: 1.1263\n",
            "Epoch 4/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m928s\u001b[0m 8s/step - accuracy: 0.7636 - loss: 0.6132 - val_accuracy: 0.6772 - val_loss: 0.8693\n",
            "Epoch 5/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m873s\u001b[0m 8s/step - accuracy: 0.7815 - loss: 0.5873 - val_accuracy: 0.7336 - val_loss: 0.7119\n",
            "Epoch 6/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m872s\u001b[0m 8s/step - accuracy: 0.8037 - loss: 0.5654 - val_accuracy: 0.7528 - val_loss: 0.6686\n",
            "Epoch 7/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m946s\u001b[0m 8s/step - accuracy: 0.8141 - loss: 0.5036 - val_accuracy: 0.7585 - val_loss: 0.6623\n",
            "Epoch 8/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m869s\u001b[0m 8s/step - accuracy: 0.7996 - loss: 0.5291 - val_accuracy: 0.7709 - val_loss: 0.6034\n",
            "Epoch 9/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m906s\u001b[0m 8s/step - accuracy: 0.8142 - loss: 0.4703 - val_accuracy: 0.7438 - val_loss: 0.7041\n",
            "Epoch 10/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m884s\u001b[0m 8s/step - accuracy: 0.8240 - loss: 0.4842 - val_accuracy: 0.7833 - val_loss: 0.5745\n",
            "Epoch 11/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m901s\u001b[0m 8s/step - accuracy: 0.8233 - loss: 0.4627 - val_accuracy: 0.7856 - val_loss: 0.5710\n",
            "Epoch 12/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m918s\u001b[0m 8s/step - accuracy: 0.8227 - loss: 0.4661 - val_accuracy: 0.7901 - val_loss: 0.5480\n",
            "Epoch 13/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m892s\u001b[0m 8s/step - accuracy: 0.8207 - loss: 0.4583 - val_accuracy: 0.7878 - val_loss: 0.6227\n",
            "Epoch 14/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m890s\u001b[0m 8s/step - accuracy: 0.8307 - loss: 0.4417 - val_accuracy: 0.8025 - val_loss: 0.5514\n",
            "Epoch 15/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m893s\u001b[0m 8s/step - accuracy: 0.8305 - loss: 0.4432 - val_accuracy: 0.7912 - val_loss: 0.5750\n",
            "CPU times: user 5h 21min 35s, sys: 13min 40s, total: 5h 35min 15s\n",
            "Wall time: 3h 44min 14s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.save('/content/drive/MyDrive/Colab Notebooks/model5.h5')\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/hist_model5.json', 'w') as f:\n",
        "    json.dump(hist_model5.history, f)"
      ],
      "metadata": {
        "id": "muOeYvwZKFny",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a13118b-6bcb-4484-e7e8-112896be74ba"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    }
  ]
}