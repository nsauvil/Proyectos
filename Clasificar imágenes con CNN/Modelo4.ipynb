{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lJbnhKjT9yxi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#from matplotlib import pyplot as plt\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "#import cv2\n",
        "import os\n",
        "#from sklearn import utils\n",
        "import json\n",
        "from keras.optimizers import Adam\n",
        "from keras.applications import VGG16\n",
        "from keras.applications import InceptionV3\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos los tensores y otros datos necesarios para el modelo\n",
        "X_train = np.load('/content/drive/MyDrive/Colab Notebooks/X_train.npy')\n",
        "#X_test = np.load('/content/drive/MyDrive/Colab Notebooks/X_test.npy')\n",
        "y_train = np.load('/content/drive/MyDrive/Colab Notebooks/y_train.npy')\n",
        "#y_test = np.load('/content/drive/MyDrive/Colab Notebooks/y_test.npy')\n",
        "target_names = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\"]\n",
        "num_targets = len(target_names)"
      ],
      "metadata": {
        "id": "Xft6nW5V-Dhk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CUARTO MODELO:\n",
        "# Transfer learning (fine-tuning)\n",
        "\n",
        "# Modelo basado en transfer learning: el modelo preentrenado sobre el que cargar los pesos de la red es libre, siempre y cuando se elija\n",
        "# cualquiera deKeras (https://keras.io/api/applications/). Se puede escoger realizar tanto featureextraction como fine-tuning,\n",
        "# aunque se valorará más positivamente (dadala complejidad de congelar capas de entrenamiento) realizar fine-tuning.\n",
        "\n",
        "base_model = InceptionV3(weights='imagenet', # También se probó VGG16, pero InceptionV3 ofrecía mejores resultados\n",
        "                   include_top=False, # Desactivamos la última capa densa de salida\n",
        "                   input_shape=(150, 150, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    print(\"Nombre layer {}\".format(layer.name))\n",
        "    print(\"\\tEs Trainable ? {}\".format(layer.trainable))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ejgcs5a-GAr",
        "outputId": "87c0b5fa-f77b-410b-9900-945ffa1a772c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Nombre layer input_layer\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_1\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_1\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_1\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_2\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_2\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_2\n",
            "\tEs Trainable ? True\n",
            "Nombre layer max_pooling2d\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_3\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_3\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_3\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_4\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_4\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_4\n",
            "\tEs Trainable ? True\n",
            "Nombre layer max_pooling2d_1\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_8\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_8\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_8\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_6\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_9\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_6\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_9\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_6\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_9\n",
            "\tEs Trainable ? True\n",
            "Nombre layer average_pooling2d\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_5\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_7\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_10\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_11\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_5\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_7\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_10\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_11\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_5\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_7\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_10\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_11\n",
            "\tEs Trainable ? True\n",
            "Nombre layer mixed0\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_15\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_15\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_15\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_13\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_16\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_13\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_16\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_13\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_16\n",
            "\tEs Trainable ? True\n",
            "Nombre layer average_pooling2d_1\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_12\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_14\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_17\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_18\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_12\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_14\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_17\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_18\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_12\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_14\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_17\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_18\n",
            "\tEs Trainable ? True\n",
            "Nombre layer mixed1\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_22\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_22\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_22\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_20\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_23\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_20\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_23\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_20\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_23\n",
            "\tEs Trainable ? True\n",
            "Nombre layer average_pooling2d_2\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_19\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_21\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_24\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_25\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_19\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_21\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_24\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_25\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_19\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_21\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_24\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_25\n",
            "\tEs Trainable ? True\n",
            "Nombre layer mixed2\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_27\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_27\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_27\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_28\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_28\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_28\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_26\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_29\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_26\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_29\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_26\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_29\n",
            "\tEs Trainable ? True\n",
            "Nombre layer max_pooling2d_2\n",
            "\tEs Trainable ? True\n",
            "Nombre layer mixed3\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_34\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_34\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_34\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_35\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_35\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_35\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_31\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_36\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_31\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_36\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_31\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_36\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_32\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_37\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_32\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_37\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_32\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_37\n",
            "\tEs Trainable ? True\n",
            "Nombre layer average_pooling2d_3\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_30\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_33\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_38\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_39\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_30\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_33\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_38\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_39\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_30\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_33\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_38\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_39\n",
            "\tEs Trainable ? True\n",
            "Nombre layer mixed4\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_44\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_44\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_44\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_45\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_45\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_45\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_41\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_46\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_41\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_46\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_41\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_46\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_42\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_47\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_42\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_47\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_42\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_47\n",
            "\tEs Trainable ? True\n",
            "Nombre layer average_pooling2d_4\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_40\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_43\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_48\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_49\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_40\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_43\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_48\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_49\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_40\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_43\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_48\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_49\n",
            "\tEs Trainable ? True\n",
            "Nombre layer mixed5\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_54\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_54\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_54\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_55\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_55\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_55\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_51\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_56\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_51\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_56\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_51\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_56\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_52\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_57\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_52\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_57\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_52\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_57\n",
            "\tEs Trainable ? True\n",
            "Nombre layer average_pooling2d_5\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_50\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_53\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_58\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_59\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_50\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_53\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_58\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_59\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_50\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_53\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_58\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_59\n",
            "\tEs Trainable ? True\n",
            "Nombre layer mixed6\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_64\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_64\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_64\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_65\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_65\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_65\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_61\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_66\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_61\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_66\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_61\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_66\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_62\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_67\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_62\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_67\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_62\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_67\n",
            "\tEs Trainable ? True\n",
            "Nombre layer average_pooling2d_6\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_60\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_63\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_68\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_69\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_60\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_63\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_68\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_69\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_60\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_63\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_68\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_69\n",
            "\tEs Trainable ? True\n",
            "Nombre layer mixed7\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_72\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_72\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_72\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_73\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_73\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_73\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_70\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_74\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_70\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_74\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_70\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_74\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_71\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_75\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_71\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_75\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_71\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_75\n",
            "\tEs Trainable ? True\n",
            "Nombre layer max_pooling2d_3\n",
            "\tEs Trainable ? True\n",
            "Nombre layer mixed8\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_80\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_80\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_80\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_77\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_81\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_77\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_81\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_77\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_81\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_78\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_79\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_82\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_83\n",
            "\tEs Trainable ? True\n",
            "Nombre layer average_pooling2d_7\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_76\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_78\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_79\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_82\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_83\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_84\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_76\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_78\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_79\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_82\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_83\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_84\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_76\n",
            "\tEs Trainable ? True\n",
            "Nombre layer mixed9_0\n",
            "\tEs Trainable ? True\n",
            "Nombre layer concatenate\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_84\n",
            "\tEs Trainable ? True\n",
            "Nombre layer mixed9\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_89\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_89\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_89\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_86\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_90\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_86\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_90\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_86\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_90\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_87\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_88\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_91\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_92\n",
            "\tEs Trainable ? True\n",
            "Nombre layer average_pooling2d_8\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_85\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_87\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_88\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_91\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_92\n",
            "\tEs Trainable ? True\n",
            "Nombre layer conv2d_93\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_85\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_87\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_88\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_91\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_92\n",
            "\tEs Trainable ? True\n",
            "Nombre layer batch_normalization_93\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_85\n",
            "\tEs Trainable ? True\n",
            "Nombre layer mixed9_1\n",
            "\tEs Trainable ? True\n",
            "Nombre layer concatenate_1\n",
            "\tEs Trainable ? True\n",
            "Nombre layer activation_93\n",
            "\tEs Trainable ? True\n",
            "Nombre layer mixed10\n",
            "\tEs Trainable ? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Primero, se eligen las capas a entrenar:\n",
        "\n",
        "layers_to_train = [\"input_layer_2\",\n",
        "                   \"conv2d\", \"batch_normalization\", \"activation\"]\n",
        "# Capas a entrenar:\n",
        "  #- Capa de entrada\n",
        "  #- Primer bloque convolucional\n",
        "\n",
        "base_model.trainable = True\n",
        "\n",
        "# Recorremos cada capa\n",
        "for layer in base_model.layers:\n",
        "    set_trainable = False\n",
        "\n",
        "    # Si la capa está en la lista, se entrena:\n",
        "    for l in layers_to_train:\n",
        "        if layer.name == l:\n",
        "            set_trainable = True\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False"
      ],
      "metadata": {
        "id": "3zsEw_X__-QD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobamos que los valores sean correctos:\n",
        "for layer in base_model.layers:\n",
        "    print(\"Nombre layer {} - Trainable {}\".format(layer.name, layer.trainable))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNC1sO_zBSlb",
        "outputId": "ff2ec128-24c7-4213-f680-a4ad48ea6c07"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre layer input_layer - Trainable False\n",
            "Nombre layer conv2d - Trainable True\n",
            "Nombre layer batch_normalization - Trainable True\n",
            "Nombre layer activation - Trainable True\n",
            "Nombre layer conv2d_1 - Trainable False\n",
            "Nombre layer batch_normalization_1 - Trainable False\n",
            "Nombre layer activation_1 - Trainable False\n",
            "Nombre layer conv2d_2 - Trainable False\n",
            "Nombre layer batch_normalization_2 - Trainable False\n",
            "Nombre layer activation_2 - Trainable False\n",
            "Nombre layer max_pooling2d - Trainable False\n",
            "Nombre layer conv2d_3 - Trainable False\n",
            "Nombre layer batch_normalization_3 - Trainable False\n",
            "Nombre layer activation_3 - Trainable False\n",
            "Nombre layer conv2d_4 - Trainable False\n",
            "Nombre layer batch_normalization_4 - Trainable False\n",
            "Nombre layer activation_4 - Trainable False\n",
            "Nombre layer max_pooling2d_1 - Trainable False\n",
            "Nombre layer conv2d_8 - Trainable False\n",
            "Nombre layer batch_normalization_8 - Trainable False\n",
            "Nombre layer activation_8 - Trainable False\n",
            "Nombre layer conv2d_6 - Trainable False\n",
            "Nombre layer conv2d_9 - Trainable False\n",
            "Nombre layer batch_normalization_6 - Trainable False\n",
            "Nombre layer batch_normalization_9 - Trainable False\n",
            "Nombre layer activation_6 - Trainable False\n",
            "Nombre layer activation_9 - Trainable False\n",
            "Nombre layer average_pooling2d - Trainable False\n",
            "Nombre layer conv2d_5 - Trainable False\n",
            "Nombre layer conv2d_7 - Trainable False\n",
            "Nombre layer conv2d_10 - Trainable False\n",
            "Nombre layer conv2d_11 - Trainable False\n",
            "Nombre layer batch_normalization_5 - Trainable False\n",
            "Nombre layer batch_normalization_7 - Trainable False\n",
            "Nombre layer batch_normalization_10 - Trainable False\n",
            "Nombre layer batch_normalization_11 - Trainable False\n",
            "Nombre layer activation_5 - Trainable False\n",
            "Nombre layer activation_7 - Trainable False\n",
            "Nombre layer activation_10 - Trainable False\n",
            "Nombre layer activation_11 - Trainable False\n",
            "Nombre layer mixed0 - Trainable False\n",
            "Nombre layer conv2d_15 - Trainable False\n",
            "Nombre layer batch_normalization_15 - Trainable False\n",
            "Nombre layer activation_15 - Trainable False\n",
            "Nombre layer conv2d_13 - Trainable False\n",
            "Nombre layer conv2d_16 - Trainable False\n",
            "Nombre layer batch_normalization_13 - Trainable False\n",
            "Nombre layer batch_normalization_16 - Trainable False\n",
            "Nombre layer activation_13 - Trainable False\n",
            "Nombre layer activation_16 - Trainable False\n",
            "Nombre layer average_pooling2d_1 - Trainable False\n",
            "Nombre layer conv2d_12 - Trainable False\n",
            "Nombre layer conv2d_14 - Trainable False\n",
            "Nombre layer conv2d_17 - Trainable False\n",
            "Nombre layer conv2d_18 - Trainable False\n",
            "Nombre layer batch_normalization_12 - Trainable False\n",
            "Nombre layer batch_normalization_14 - Trainable False\n",
            "Nombre layer batch_normalization_17 - Trainable False\n",
            "Nombre layer batch_normalization_18 - Trainable False\n",
            "Nombre layer activation_12 - Trainable False\n",
            "Nombre layer activation_14 - Trainable False\n",
            "Nombre layer activation_17 - Trainable False\n",
            "Nombre layer activation_18 - Trainable False\n",
            "Nombre layer mixed1 - Trainable False\n",
            "Nombre layer conv2d_22 - Trainable False\n",
            "Nombre layer batch_normalization_22 - Trainable False\n",
            "Nombre layer activation_22 - Trainable False\n",
            "Nombre layer conv2d_20 - Trainable False\n",
            "Nombre layer conv2d_23 - Trainable False\n",
            "Nombre layer batch_normalization_20 - Trainable False\n",
            "Nombre layer batch_normalization_23 - Trainable False\n",
            "Nombre layer activation_20 - Trainable False\n",
            "Nombre layer activation_23 - Trainable False\n",
            "Nombre layer average_pooling2d_2 - Trainable False\n",
            "Nombre layer conv2d_19 - Trainable False\n",
            "Nombre layer conv2d_21 - Trainable False\n",
            "Nombre layer conv2d_24 - Trainable False\n",
            "Nombre layer conv2d_25 - Trainable False\n",
            "Nombre layer batch_normalization_19 - Trainable False\n",
            "Nombre layer batch_normalization_21 - Trainable False\n",
            "Nombre layer batch_normalization_24 - Trainable False\n",
            "Nombre layer batch_normalization_25 - Trainable False\n",
            "Nombre layer activation_19 - Trainable False\n",
            "Nombre layer activation_21 - Trainable False\n",
            "Nombre layer activation_24 - Trainable False\n",
            "Nombre layer activation_25 - Trainable False\n",
            "Nombre layer mixed2 - Trainable False\n",
            "Nombre layer conv2d_27 - Trainable False\n",
            "Nombre layer batch_normalization_27 - Trainable False\n",
            "Nombre layer activation_27 - Trainable False\n",
            "Nombre layer conv2d_28 - Trainable False\n",
            "Nombre layer batch_normalization_28 - Trainable False\n",
            "Nombre layer activation_28 - Trainable False\n",
            "Nombre layer conv2d_26 - Trainable False\n",
            "Nombre layer conv2d_29 - Trainable False\n",
            "Nombre layer batch_normalization_26 - Trainable False\n",
            "Nombre layer batch_normalization_29 - Trainable False\n",
            "Nombre layer activation_26 - Trainable False\n",
            "Nombre layer activation_29 - Trainable False\n",
            "Nombre layer max_pooling2d_2 - Trainable False\n",
            "Nombre layer mixed3 - Trainable False\n",
            "Nombre layer conv2d_34 - Trainable False\n",
            "Nombre layer batch_normalization_34 - Trainable False\n",
            "Nombre layer activation_34 - Trainable False\n",
            "Nombre layer conv2d_35 - Trainable False\n",
            "Nombre layer batch_normalization_35 - Trainable False\n",
            "Nombre layer activation_35 - Trainable False\n",
            "Nombre layer conv2d_31 - Trainable False\n",
            "Nombre layer conv2d_36 - Trainable False\n",
            "Nombre layer batch_normalization_31 - Trainable False\n",
            "Nombre layer batch_normalization_36 - Trainable False\n",
            "Nombre layer activation_31 - Trainable False\n",
            "Nombre layer activation_36 - Trainable False\n",
            "Nombre layer conv2d_32 - Trainable False\n",
            "Nombre layer conv2d_37 - Trainable False\n",
            "Nombre layer batch_normalization_32 - Trainable False\n",
            "Nombre layer batch_normalization_37 - Trainable False\n",
            "Nombre layer activation_32 - Trainable False\n",
            "Nombre layer activation_37 - Trainable False\n",
            "Nombre layer average_pooling2d_3 - Trainable False\n",
            "Nombre layer conv2d_30 - Trainable False\n",
            "Nombre layer conv2d_33 - Trainable False\n",
            "Nombre layer conv2d_38 - Trainable False\n",
            "Nombre layer conv2d_39 - Trainable False\n",
            "Nombre layer batch_normalization_30 - Trainable False\n",
            "Nombre layer batch_normalization_33 - Trainable False\n",
            "Nombre layer batch_normalization_38 - Trainable False\n",
            "Nombre layer batch_normalization_39 - Trainable False\n",
            "Nombre layer activation_30 - Trainable False\n",
            "Nombre layer activation_33 - Trainable False\n",
            "Nombre layer activation_38 - Trainable False\n",
            "Nombre layer activation_39 - Trainable False\n",
            "Nombre layer mixed4 - Trainable False\n",
            "Nombre layer conv2d_44 - Trainable False\n",
            "Nombre layer batch_normalization_44 - Trainable False\n",
            "Nombre layer activation_44 - Trainable False\n",
            "Nombre layer conv2d_45 - Trainable False\n",
            "Nombre layer batch_normalization_45 - Trainable False\n",
            "Nombre layer activation_45 - Trainable False\n",
            "Nombre layer conv2d_41 - Trainable False\n",
            "Nombre layer conv2d_46 - Trainable False\n",
            "Nombre layer batch_normalization_41 - Trainable False\n",
            "Nombre layer batch_normalization_46 - Trainable False\n",
            "Nombre layer activation_41 - Trainable False\n",
            "Nombre layer activation_46 - Trainable False\n",
            "Nombre layer conv2d_42 - Trainable False\n",
            "Nombre layer conv2d_47 - Trainable False\n",
            "Nombre layer batch_normalization_42 - Trainable False\n",
            "Nombre layer batch_normalization_47 - Trainable False\n",
            "Nombre layer activation_42 - Trainable False\n",
            "Nombre layer activation_47 - Trainable False\n",
            "Nombre layer average_pooling2d_4 - Trainable False\n",
            "Nombre layer conv2d_40 - Trainable False\n",
            "Nombre layer conv2d_43 - Trainable False\n",
            "Nombre layer conv2d_48 - Trainable False\n",
            "Nombre layer conv2d_49 - Trainable False\n",
            "Nombre layer batch_normalization_40 - Trainable False\n",
            "Nombre layer batch_normalization_43 - Trainable False\n",
            "Nombre layer batch_normalization_48 - Trainable False\n",
            "Nombre layer batch_normalization_49 - Trainable False\n",
            "Nombre layer activation_40 - Trainable False\n",
            "Nombre layer activation_43 - Trainable False\n",
            "Nombre layer activation_48 - Trainable False\n",
            "Nombre layer activation_49 - Trainable False\n",
            "Nombre layer mixed5 - Trainable False\n",
            "Nombre layer conv2d_54 - Trainable False\n",
            "Nombre layer batch_normalization_54 - Trainable False\n",
            "Nombre layer activation_54 - Trainable False\n",
            "Nombre layer conv2d_55 - Trainable False\n",
            "Nombre layer batch_normalization_55 - Trainable False\n",
            "Nombre layer activation_55 - Trainable False\n",
            "Nombre layer conv2d_51 - Trainable False\n",
            "Nombre layer conv2d_56 - Trainable False\n",
            "Nombre layer batch_normalization_51 - Trainable False\n",
            "Nombre layer batch_normalization_56 - Trainable False\n",
            "Nombre layer activation_51 - Trainable False\n",
            "Nombre layer activation_56 - Trainable False\n",
            "Nombre layer conv2d_52 - Trainable False\n",
            "Nombre layer conv2d_57 - Trainable False\n",
            "Nombre layer batch_normalization_52 - Trainable False\n",
            "Nombre layer batch_normalization_57 - Trainable False\n",
            "Nombre layer activation_52 - Trainable False\n",
            "Nombre layer activation_57 - Trainable False\n",
            "Nombre layer average_pooling2d_5 - Trainable False\n",
            "Nombre layer conv2d_50 - Trainable False\n",
            "Nombre layer conv2d_53 - Trainable False\n",
            "Nombre layer conv2d_58 - Trainable False\n",
            "Nombre layer conv2d_59 - Trainable False\n",
            "Nombre layer batch_normalization_50 - Trainable False\n",
            "Nombre layer batch_normalization_53 - Trainable False\n",
            "Nombre layer batch_normalization_58 - Trainable False\n",
            "Nombre layer batch_normalization_59 - Trainable False\n",
            "Nombre layer activation_50 - Trainable False\n",
            "Nombre layer activation_53 - Trainable False\n",
            "Nombre layer activation_58 - Trainable False\n",
            "Nombre layer activation_59 - Trainable False\n",
            "Nombre layer mixed6 - Trainable False\n",
            "Nombre layer conv2d_64 - Trainable False\n",
            "Nombre layer batch_normalization_64 - Trainable False\n",
            "Nombre layer activation_64 - Trainable False\n",
            "Nombre layer conv2d_65 - Trainable False\n",
            "Nombre layer batch_normalization_65 - Trainable False\n",
            "Nombre layer activation_65 - Trainable False\n",
            "Nombre layer conv2d_61 - Trainable False\n",
            "Nombre layer conv2d_66 - Trainable False\n",
            "Nombre layer batch_normalization_61 - Trainable False\n",
            "Nombre layer batch_normalization_66 - Trainable False\n",
            "Nombre layer activation_61 - Trainable False\n",
            "Nombre layer activation_66 - Trainable False\n",
            "Nombre layer conv2d_62 - Trainable False\n",
            "Nombre layer conv2d_67 - Trainable False\n",
            "Nombre layer batch_normalization_62 - Trainable False\n",
            "Nombre layer batch_normalization_67 - Trainable False\n",
            "Nombre layer activation_62 - Trainable False\n",
            "Nombre layer activation_67 - Trainable False\n",
            "Nombre layer average_pooling2d_6 - Trainable False\n",
            "Nombre layer conv2d_60 - Trainable False\n",
            "Nombre layer conv2d_63 - Trainable False\n",
            "Nombre layer conv2d_68 - Trainable False\n",
            "Nombre layer conv2d_69 - Trainable False\n",
            "Nombre layer batch_normalization_60 - Trainable False\n",
            "Nombre layer batch_normalization_63 - Trainable False\n",
            "Nombre layer batch_normalization_68 - Trainable False\n",
            "Nombre layer batch_normalization_69 - Trainable False\n",
            "Nombre layer activation_60 - Trainable False\n",
            "Nombre layer activation_63 - Trainable False\n",
            "Nombre layer activation_68 - Trainable False\n",
            "Nombre layer activation_69 - Trainable False\n",
            "Nombre layer mixed7 - Trainable False\n",
            "Nombre layer conv2d_72 - Trainable False\n",
            "Nombre layer batch_normalization_72 - Trainable False\n",
            "Nombre layer activation_72 - Trainable False\n",
            "Nombre layer conv2d_73 - Trainable False\n",
            "Nombre layer batch_normalization_73 - Trainable False\n",
            "Nombre layer activation_73 - Trainable False\n",
            "Nombre layer conv2d_70 - Trainable False\n",
            "Nombre layer conv2d_74 - Trainable False\n",
            "Nombre layer batch_normalization_70 - Trainable False\n",
            "Nombre layer batch_normalization_74 - Trainable False\n",
            "Nombre layer activation_70 - Trainable False\n",
            "Nombre layer activation_74 - Trainable False\n",
            "Nombre layer conv2d_71 - Trainable False\n",
            "Nombre layer conv2d_75 - Trainable False\n",
            "Nombre layer batch_normalization_71 - Trainable False\n",
            "Nombre layer batch_normalization_75 - Trainable False\n",
            "Nombre layer activation_71 - Trainable False\n",
            "Nombre layer activation_75 - Trainable False\n",
            "Nombre layer max_pooling2d_3 - Trainable False\n",
            "Nombre layer mixed8 - Trainable False\n",
            "Nombre layer conv2d_80 - Trainable False\n",
            "Nombre layer batch_normalization_80 - Trainable False\n",
            "Nombre layer activation_80 - Trainable False\n",
            "Nombre layer conv2d_77 - Trainable False\n",
            "Nombre layer conv2d_81 - Trainable False\n",
            "Nombre layer batch_normalization_77 - Trainable False\n",
            "Nombre layer batch_normalization_81 - Trainable False\n",
            "Nombre layer activation_77 - Trainable False\n",
            "Nombre layer activation_81 - Trainable False\n",
            "Nombre layer conv2d_78 - Trainable False\n",
            "Nombre layer conv2d_79 - Trainable False\n",
            "Nombre layer conv2d_82 - Trainable False\n",
            "Nombre layer conv2d_83 - Trainable False\n",
            "Nombre layer average_pooling2d_7 - Trainable False\n",
            "Nombre layer conv2d_76 - Trainable False\n",
            "Nombre layer batch_normalization_78 - Trainable False\n",
            "Nombre layer batch_normalization_79 - Trainable False\n",
            "Nombre layer batch_normalization_82 - Trainable False\n",
            "Nombre layer batch_normalization_83 - Trainable False\n",
            "Nombre layer conv2d_84 - Trainable False\n",
            "Nombre layer batch_normalization_76 - Trainable False\n",
            "Nombre layer activation_78 - Trainable False\n",
            "Nombre layer activation_79 - Trainable False\n",
            "Nombre layer activation_82 - Trainable False\n",
            "Nombre layer activation_83 - Trainable False\n",
            "Nombre layer batch_normalization_84 - Trainable False\n",
            "Nombre layer activation_76 - Trainable False\n",
            "Nombre layer mixed9_0 - Trainable False\n",
            "Nombre layer concatenate - Trainable False\n",
            "Nombre layer activation_84 - Trainable False\n",
            "Nombre layer mixed9 - Trainable False\n",
            "Nombre layer conv2d_89 - Trainable False\n",
            "Nombre layer batch_normalization_89 - Trainable False\n",
            "Nombre layer activation_89 - Trainable False\n",
            "Nombre layer conv2d_86 - Trainable False\n",
            "Nombre layer conv2d_90 - Trainable False\n",
            "Nombre layer batch_normalization_86 - Trainable False\n",
            "Nombre layer batch_normalization_90 - Trainable False\n",
            "Nombre layer activation_86 - Trainable False\n",
            "Nombre layer activation_90 - Trainable False\n",
            "Nombre layer conv2d_87 - Trainable False\n",
            "Nombre layer conv2d_88 - Trainable False\n",
            "Nombre layer conv2d_91 - Trainable False\n",
            "Nombre layer conv2d_92 - Trainable False\n",
            "Nombre layer average_pooling2d_8 - Trainable False\n",
            "Nombre layer conv2d_85 - Trainable False\n",
            "Nombre layer batch_normalization_87 - Trainable False\n",
            "Nombre layer batch_normalization_88 - Trainable False\n",
            "Nombre layer batch_normalization_91 - Trainable False\n",
            "Nombre layer batch_normalization_92 - Trainable False\n",
            "Nombre layer conv2d_93 - Trainable False\n",
            "Nombre layer batch_normalization_85 - Trainable False\n",
            "Nombre layer activation_87 - Trainable False\n",
            "Nombre layer activation_88 - Trainable False\n",
            "Nombre layer activation_91 - Trainable False\n",
            "Nombre layer activation_92 - Trainable False\n",
            "Nombre layer batch_normalization_93 - Trainable False\n",
            "Nombre layer activation_85 - Trainable False\n",
            "Nombre layer mixed9_1 - Trainable False\n",
            "Nombre layer concatenate_1 - Trainable False\n",
            "Nombre layer activation_93 - Trainable False\n",
            "Nombre layer mixed10 - Trainable False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = Sequential([ #Añadimos las capas densas\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'), # Capa densa 1\n",
        "    Dense(num_targets, activation='softmax') # Capa de salida final\n",
        "])"
      ],
      "metadata": {
        "id": "341sw_BwBsIS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4.compile(optimizer=\"adam\",\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "FKePp265Cmcg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "\n",
        "hist_model4 = model4.fit(X_train, y_train,\n",
        "                  batch_size = 32,\n",
        "                  epochs = 15,\n",
        "                  validation_split = 0.20,\n",
        "                  callbacks  = [early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlrWD-vpC7tu",
        "outputId": "1cb8ebf6-9aff-4f8a-83e1-6f7a91787ebc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m577s\u001b[0m 5s/step - accuracy: 0.6904 - loss: 3.4059 - val_accuracy: 0.8038 - val_loss: 1.1572\n",
            "Epoch 2/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m582s\u001b[0m 5s/step - accuracy: 0.9033 - loss: 0.4118 - val_accuracy: 0.8681 - val_loss: 0.6593\n",
            "Epoch 3/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m558s\u001b[0m 5s/step - accuracy: 0.9140 - loss: 0.2976 - val_accuracy: 0.8681 - val_loss: 0.6066\n",
            "Epoch 4/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m604s\u001b[0m 5s/step - accuracy: 0.9490 - loss: 0.1465 - val_accuracy: 0.8873 - val_loss: 0.5649\n",
            "Epoch 5/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m617s\u001b[0m 5s/step - accuracy: 0.9632 - loss: 0.1191 - val_accuracy: 0.8884 - val_loss: 0.6734\n",
            "Epoch 6/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m523s\u001b[0m 5s/step - accuracy: 0.9700 - loss: 0.0871 - val_accuracy: 0.8850 - val_loss: 0.6761\n",
            "Epoch 7/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m601s\u001b[0m 5s/step - accuracy: 0.9820 - loss: 0.0521 - val_accuracy: 0.8985 - val_loss: 0.5680\n",
            "Epoch 8/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m567s\u001b[0m 5s/step - accuracy: 0.9942 - loss: 0.0206 - val_accuracy: 0.8963 - val_loss: 0.5679\n",
            "Epoch 9/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m615s\u001b[0m 5s/step - accuracy: 0.9798 - loss: 0.0663 - val_accuracy: 0.8839 - val_loss: 0.6301\n",
            "Epoch 10/15\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m564s\u001b[0m 5s/step - accuracy: 0.9924 - loss: 0.0311 - val_accuracy: 0.8963 - val_loss: 0.6447\n",
            "CPU times: user 2h 19min 16s, sys: 3min 25s, total: 2h 22min 42s\n",
            "Wall time: 1h 37min 51s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.save('/content/drive/MyDrive/Colab Notebooks/model4.h5')\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/hist_model4.json', 'w') as f:\n",
        "    json.dump(hist_model4.history, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V0KRrcx_dlf",
        "outputId": "6873c379-1144-444b-f554-297bdc14d01d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    }
  ]
}